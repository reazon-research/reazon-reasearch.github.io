<!doctype html>
<html class="no-js"  lang="en" >

<head><meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-S1KMDX1V1H"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-S1KMDX1V1H');
    </script>
    
  <link rel="author" title="About these documents" href="../about.html" /><link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="(2024-03-02) ALOHAとACTを用いた模倣学習実験の再現方法" href="2024-03-02-how-to-run-aloha-developers.agirobots.com.html" /><link rel="prev" title="(2024-10-21) 大規模日本語音声による事前学習モデルWav2Vec2を公開" href="2024-10-21-Wav2Vec2-base-release.html" />
  <link rel="canonical" href="https://research.reazon.jp/blog/2024-08-01-ReazonSpeech.html" />
  
  <title>(2024-08-01) ReazonSpeech v2.1: Setting a New Standard in Japanese ASR - Reazon Human Interaction Lab</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Condensed:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
  <link rel="stylesheet" type="text/css" href="../_static/style.css" />
  <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
  </head>

<body id="blog-2024-08-01-ReazonSpeech">
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
    <symbol id="svg-arrow" viewBox="0 0 14 8">
      <svg viewBox="0 0 14 8" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7 2.82801L2.05 7.77801L0.635998 6.36401L7 1.47024e-05L13.364 6.36402L11.95 7.77802L7 2.82801Z"
          fill="currentColor" />
      </svg>
    </symbol>
    <symbol id="svg-toc-menu">
      <svg width="19" height="17" viewBox="0 0 19 17" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path
          d="M19 15V17H1V15H19ZM4.596 0.903999L6.01 2.318L2.828 5.5L6.01 8.682L4.596 10.096L0 5.5L4.596 0.903999ZM19 8V10H10V8H19ZM19 0.999999V3H10V0.999999H19Z"
          fill="currentColor" />
      </svg>
    </symbol>
    <symbol id="svg-close">
      <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path
          d="M8 6.2225L14.2225 0L16 1.7775L9.7775 8L16 14.2225L14.2225 16L8 9.7775L1.7775 16L0 14.2225L6.2225 8L0 1.7775L1.7775 0L8 6.2225Z"
          fill="currentColor" />
      </svg>
    </symbol>
    <symbol id="svg-arrow-left">
      <svg width="10" height="17" viewBox="0 0 10 17" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M3.6359 8.5L10 15.1114L8.18205 17L5.82128e-07 8.5L8.18205 -7.9465e-08L10 1.88859L3.6359 8.5Z"
          fill="currentColor" />
      </svg>
    </symbol>
  </svg>
  <div id="global_nav"></div>
  <div class="Container">
    <aside id="sidebar" class="Sidebar" aria-label="Sidebar">
    <div class="Sidebar__animationBg"></div>
    <div class="Sidebar__container">
        <div class="Sidebar__inner">
            <a class="Sidebar__logo" href="../index.html">
                
                <h1>
                    <img class="Sidebar__logoImage--light" src="../_static/logo.png" />
                    <img class="Sidebar__logoImage--dark" src="../_static/logo-dark.png" />
                </h1>
                
            </a>
            <div class="Sidebar__tree Tree"><ul class="current">
<li class="toctree-l1 Tree__item"><a class="reference internal" href="../about.html">About</a></li>
<li class="toctree-l1 Tree__item Tree__item--has-children"><a class="reference internal" href="../projects/index.html">Projects</a><input class="Tree_itemToggleCheckbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="Tree__itemToggle" for="toctree-checkbox-1"><i class="Tree__itemToggleIcon"><svg><use href="#svg-arrow"></use></svg></i></label><ul>
<li class="toctree-l2 Tree__item Tree__item--has-children"><a class="reference internal" href="../projects/ReazonSpeech/index.html">ReazonSpeech</a><input class="Tree_itemToggleCheckbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="Tree__itemToggle" for="toctree-checkbox-2"><i class="Tree__itemToggleIcon"><svg><use href="#svg-arrow"></use></svg></i></label><ul>
<li class="toctree-l3 Tree__item"><a class="reference internal" href="../projects/ReazonSpeech/quickstart.html">クイックスタート</a></li>
<li class="toctree-l3 Tree__item"><a class="reference internal" href="../projects/ReazonSpeech/howto.html">HowToガイド</a></li>
<li class="toctree-l3 Tree__item Tree__item--has-children"><a class="reference internal" href="../projects/ReazonSpeech/api/index.html">APIリファレンス</a><input class="Tree_itemToggleCheckbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="Tree__itemToggle" for="toctree-checkbox-3"><i class="Tree__itemToggleIcon"><svg><use href="#svg-arrow"></use></svg></i></label><ul>
<li class="toctree-l4 Tree__item"><a class="reference internal" href="../projects/ReazonSpeech/api/reazonspeech.nemo.asr.html">reazonspeech.nemo.asr</a></li>
<li class="toctree-l4 Tree__item"><a class="reference internal" href="../projects/ReazonSpeech/api/reazonspeech.k2.asr.html">reazonspeech.k2.asr</a></li>
<li class="toctree-l4 Tree__item"><a class="reference internal" href="../projects/ReazonSpeech/api/reazonspeech.espnet.asr.html">reazonspeech.espnet.asr</a></li>
<li class="toctree-l4 Tree__item"><a class="reference internal" href="../projects/ReazonSpeech/api/reazonspeech.espnet.oneseg.html">reazonspeech.espnet.oneseg</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 Tree__item Tree__item--has-children"><a class="reference internal" href="../news/index.html">News</a><input class="Tree_itemToggleCheckbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="Tree__itemToggle" for="toctree-checkbox-4"><i class="Tree__itemToggleIcon"><svg><use href="#svg-arrow"></use></svg></i></label><ul>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="../news/reazonspeech.html">超高精度で商用利用可能な純国産の日本語音声認識モデル「ReazonSpeech」を無償公開</a></li>
</ul>
</li>
<li class="toctree-l1 current Tree__item Tree__item--has-children"><a class="reference internal" href="index.html">Blog</a><input checked="" class="Tree_itemToggleCheckbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="Tree__itemToggle" for="toctree-checkbox-5"><i class="Tree__itemToggleIcon"><svg><use href="#svg-arrow"></use></svg></i></label><ul class="current">
<li class="toctree-l2 Tree__item"><a class="reference internal" href="2024-11-06-openarm-study-group-01.html">(2024-11-06) 第1回 OpenArm勉強会を開催しました!</a></li>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="2024-10-21-Wav2Vec2-base-release.html">(2024-10-21) 大規模日本語音声による事前学習モデルWav2Vec2を公開</a></li>
<li class="toctree-l2 current Tree__item current-page"><a class="current reference internal" href="#">(2024-08-01) ReazonSpeech v2.1: Setting a New Standard in Japanese ASR</a></li>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="2024-03-02-how-to-run-aloha-developers.agirobots.com.html">(2024-03-02) ALOHAとACTを用いた模倣学習実験の再現方法</a></li>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="2024-02-14-ReazonSpeech.html">(2024-02-14) ReazonSpeech v2.0: 音声モデルの高速化とコーパスの大幅な拡大</a></li>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="2023-04-04-ReazonSpeech.html">(2023-04-04) ReazonSpeechの最新モデルを公開しました</a></li>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="2023-01-15-ReazonSpeech-ESP32.html">(2023-01-15) スマホの通話内容をReazonSpeechで音声認識してSlackに転送する</a></li>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="2023-01-15-DDS-performance.html">(2023-01-15) 分散ROS2 FastDDS/CycloneDDS のパフォーマンス評価</a></li>
</ul>
</li>
<li class="toctree-l1 Tree__item"><a class="reference internal" href="../publications.html">Publications</a></li>
<li class="toctree-l1 Tree__item"><a class="reference internal" href="../careers.html">Careers</a></li>
</ul>
</div>
            <div class="Sidebar__search Search">
                <i class="Search__icon">
                    <svg width="22" height="21" viewBox="0 0 21 21" fill="none" xmlns="http://www.w3.org/2000/svg">
                        <path
                            d="M16.031 14.617L20.314 18.899L18.899 20.314L14.617 16.031C13.0237 17.3082 11.042 18.0029 9 18C4.032 18 0 13.968 0 9C0 4.032 4.032 0 9 0C13.968 0 18 4.032 18 9C18.0029 11.042 17.3082 13.0237 16.031 14.617ZM14.025 13.875C15.2941 12.5699 16.0029 10.8204 16 9C16 5.132 12.867 2 9 2C5.132 2 2 5.132 2 9C2 12.867 5.132 16 9 16C10.8204 16.0029 12.5699 15.2941 13.875 14.025L14.025 13.875Z"
                            fill="currentColor" />
                    </svg>
                </i>
                <form class="Search__form" method="get" action="../search.html" role="search">
                    <input class="Search__formText" placeholder=" Search" name="q" aria-label=" Search" />
                    <input type="hidden" name="check_keywords" value="yes" />
                    <input type="hidden" name="area" value="default" />
                </form>
            </div>
        </div>
    </div>
</aside>
    <div class="Container__inner">
      
      <script>document.body.dataset.theme = localStorage.getItem("theme") || "auto";</script>



<main class="Page">
    <header class="Page__header">
        
        <div class="Page__headerParent">Blog：</div>
        
        <h1>(2024-08-01) ReazonSpeech v2.1: Setting a New Standard in Japanese ASR </h1>
        
    </header>
    <article class="Page__body">
        <section id="reazonspeech-v2-1-setting-a-new-standard-in-japanese-asr">
<h1>(2024-08-01) ReazonSpeech v2.1: Setting a New Standard in Japanese ASR<a class="headerlink" href="#reazonspeech-v2-1-setting-a-new-standard-in-japanese-asr" title="Permalink to this heading">¶</a></h1>
<p>Today, we’re excited to announce ReazonSpeech v2.1. In this release, we
publish ReazonSpeech-k2-v2, an open-source Japanese ASR model which sets
new records in benchmark tests. It is built on the
<a class="reference external" href="https://k2-fsa.org/">Next-gen Kaldi framework</a> and distributed in
the platform-neutral
<a class="reference external" href="https://github.com/onnx/onnx">Open Neural Network Exchange (ONNX) format</a>.
ReazonSpeech-k2-v2 excels in accuracy, compactness, and inference speed,
and can run on-device without GPU.</p>
<p>We published the ReazonSpeech-k2-v2 model under the Apache 2.0 license. The
model files and the inference code are readily available on
<a class="reference external" href="https://huggingface.co/reazon-research/reazonspeech-k2-v2">Hugging Face</a>
and
<a class="reference external" href="https://github.com/reazon-research/ReazonSpeech">GitHub</a>.</p>
<figure class="align-default" id="id5">
<img alt="../_images/cer2.png" src="../_images/cer2.png" />
<figcaption>
<p><span class="caption-text"><strong>Figure 1: ReazonSpeech v2.1 on common Japanese ASR benchmark tests</strong></span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<section id="what-is-reazonspeech-v2-1">
<h2>What is ReazonSpeech v2.1?<a class="headerlink" href="#what-is-reazonspeech-v2-1" title="Permalink to this heading">¶</a></h2>
<p>ReazonSpeech v2.1 represents the latest iteration of Reazon Human Interaction
Lab’s ASR research. This release introduces a new Japanese ASR model that:</p>
<ul class="simple">
<li><p>Outperforms existing Japanese ASR models on JSUT-BASIC5000 <a class="footnote-reference brackets" href="#jsut-basic5000" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>,
Common Voice v8.0 <a class="footnote-reference brackets" href="#cv" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>, and TEDxJP-10K <a class="footnote-reference brackets" href="#tedx" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a> benchmark sets (see the
chart above).</p></li>
<li><p>Excels in compactness, only having 159M parameters.</p></li>
<li><p>Excels in inference speed, one of the fastest models to process short audio inputs.</p></li>
</ul>
<p>What enables such outstanding performance is the state-of-the-art Transformer
called Zipformer <a class="footnote-reference brackets" href="#zipformer" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a>. We trained this novel network architecture on
35,000 hours of <a class="reference external" href="https://huggingface.co/datasets/reazon-research/reazonspeech">Reazonspeech v2.0 corpus</a>,
which revealed a best-in-class performance.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>For further details about the ReazonSpeech-k2-v2 model, the full training
recipe is available on <a class="reference external" href="https://github.com/k2-fsa/icefall/tree/master/egs/reazonspeech/ASR">k2-fsa/icefall</a>.</p>
</div>
</section>
<section id="easy-deployment-with-onnx">
<h2>Easy deployment with ONNX<a class="headerlink" href="#easy-deployment-with-onnx" title="Permalink to this heading">¶</a></h2>
<p>The ReazonSpeech-k2-v2 model is available in the ONNX format, significantly
enhancing its versatility across a wide range of platforms. Leveraging the ONNX
runtime, which is independent of the PyTorch framework, simplifies the setup
process, facilitating seamless integration across diverse environments. This
adaptability ensures practical application on various devices even without GPU,
including Linux, macOS, Windows, embedded systems, Android, and iOS.</p>
<p>For more details about the supported platforms, please refer to the
<a class="reference external" href="https://k2-fsa.github.io/sherpa/onnx/index.html">Sherpa-ONNX’s documentation</a>.</p>
</section>
<section id="reduce-memory-footprint-with-quantization">
<h2>Reduce memory footprint with quantization<a class="headerlink" href="#reduce-memory-footprint-with-quantization" title="Permalink to this heading">¶</a></h2>
<p>We also released a <code class="docutils literal notranslate"><span class="pre">int8</span></code>-quantized version of the ReazonSpeech-k2-v2 model.
The quantized model exhibits a significantly smaller footprint, as shown
in the following table.</p>
<div class="table-wrapper docutils container" id="id6">
<table class="docutils align-default" id="id6">
<caption><span class="caption-text">Table 1: The effects of quantization on model size</span><a class="headerlink" href="#id6" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>FILE</p></th>
<th class="head"><p>FILE SIZE (FP32)</p></th>
<th class="head"><p>FILE SIZE (INT8)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Encoder</p></td>
<td><p>565 MB</p></td>
<td><p>148 MB</p></td>
</tr>
<tr class="row-odd"><td><p>Decoder</p></td>
<td><p>12 MB</p></td>
<td><p>3 MB</p></td>
</tr>
<tr class="row-even"><td><p>Joiner</p></td>
<td><p>11 MB</p></td>
<td><p>3 MB</p></td>
</tr>
</tbody>
</table>
</div>
<p>These quantized models are up to 10x smaller than comparable ASR models like
Whisper-Large-v3, enabling their deployment on a wide range of devices with
computational constraints. Notably, when used with a non-quantized decoder,
these quantized models maintain accuracy levels comparable to their
non-quantized counterparts. This enables the deployment of our model even on
devices with very limited computational capacity.</p>
<div class="table-wrapper docutils container" id="id7">
<table class="docutils align-default" id="id7">
<caption><span class="caption-text">Table 2: The effects of quantization on accuracy</span><a class="headerlink" href="#id7" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Model Name</p></th>
<th class="head"><p>JSUT</p></th>
<th class="head"><p>Common Voice</p></th>
<th class="head"><p>TEDxJP-10K</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ReazonSpeech-k2-v2</p></td>
<td><p>6.45</p></td>
<td><p>7.85</p></td>
<td><p>9.09</p></td>
</tr>
<tr class="row-odd"><td><p>ReazonSpeech-k2-v2 (int8)</p></td>
<td><p>6.63</p></td>
<td><p>8.19</p></td>
<td><p>9.86</p></td>
</tr>
<tr class="row-even"><td><p>ReazonSpeech-k2-v2 (int8-fp32)</p></td>
<td><p>6.45</p></td>
<td><p>7.87</p></td>
<td><p>9.15</p></td>
</tr>
<tr class="row-odd"><td><p>Whisper Large-v3</p></td>
<td><p>7.18</p></td>
<td><p>8.18</p></td>
<td><p>9.96</p></td>
</tr>
<tr class="row-even"><td><p>ReazonSpeech-NeMo-v2</p></td>
<td><p>7.31</p></td>
<td><p>8.81</p></td>
<td><p>10.42</p></td>
</tr>
<tr class="row-odd"><td><p>ReazonSpeech-ESPnet-v2</p></td>
<td><p>6.89</p></td>
<td><p>8.27</p></td>
<td><p>9.28</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="future-goals">
<h2>Future goals<a class="headerlink" href="#future-goals" title="Permalink to this heading">¶</a></h2>
<p>With this release, we have significantly enhanced both the speed and accuracy
of our Japanese ASR models. By making our model open-source on the K2
Sherpa-ONNX platform, we have greatly improved accessibility for a broad range
of users and developers across various platforms.</p>
<p>Looking ahead, we are committed to further advancing our models by expanding
our dataset, developing streaming ASR capabilities, and incorporating
multilingual data to create an exceptional bilingual English-Japanese ASR
model.</p>
<p>This release represents a major milestone, and we are excited to continue
pushing the boundaries of Japanese speech processing technology in the future.
Currently, ReazonSpeech-k2-v2 can process longer segments of audio with the
help of voice activity detection (VAD). In the future, we plan to release a
streaming version of this model which can innately support real-time
transcription.</p>
</section>
<section id="footnotes">
<h2>Footnotes<a class="headerlink" href="#footnotes" title="Permalink to this heading">¶</a></h2>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="jsut-basic5000" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Ryosuke Sonobe, Shinnosuke Takamichi and Hiroshi Saruwatari,  “JSUT corpus: free large-scale Japanese speech corpus for end-to-end speech synthesis,” arXiv preprint, 1711.00354, 2017.</p>
</aside>
<aside class="footnote brackets" id="cv" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://commonvoice.mozilla.org/">https://commonvoice.mozilla.org/</a></p>
</aside>
<aside class="footnote brackets" id="tedx" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://github.com/laboroai/TEDxJP-10K">https://github.com/laboroai/TEDxJP-10K</a></p>
</aside>
<aside class="footnote brackets" id="zipformer" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">4</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://arxiv.org/abs/2310.11230">https://arxiv.org/abs/2310.11230</a></p>
</aside>
</aside>
</section>
</section>

    </article>
    <aside class="Page__toc Toc">
        
        
        <div class="Toc__inner">
            <div class="Toc__title">
                <span>Index</span>
            </div>
            <div class="Toc__tree">
                <ul>
<li><a class="reference internal" href="#">(2024-08-01) ReazonSpeech v2.1: Setting a New Standard in Japanese ASR</a><ul>
<li><a class="reference internal" href="#what-is-reazonspeech-v2-1">What is ReazonSpeech v2.1?</a></li>
<li><a class="reference internal" href="#easy-deployment-with-onnx">Easy deployment with ONNX</a></li>
<li><a class="reference internal" href="#reduce-memory-footprint-with-quantization">Reduce memory footprint with quantization</a></li>
<li><a class="reference internal" href="#future-goals">Future goals</a></li>
<li><a class="reference internal" href="#footnotes">Footnotes</a></li>
</ul>
</li>
</ul>

            </div>
        </div>
        
        
    </aside>
</main>

    </div>
  </div>
  <footer class="Footer">
    <div class="Footer__copyright">
        Copyright &copy; 2023, Human Interaction Laboratory
    </div>
    <div class="Footer__toolButton ToolButton">
        <div class="ToolButton__viewMode">
            <div class="ToolButton__viewModeLabel">View Mode</div>
            <button class="ToolButton__viewModeButton ToolButton__viewModeButton--dark">Night Mode</button>
            <button class="ToolButton__viewModeButton ToolButton__viewModeButton--light">Day Mode</button>
            <button class="ToolButton__viewModeButton ToolButton__viewModeButton--system">System Setting</button>
        </div>
<!--
        <div class="ToolButton__languageMode">
            <div class="ToolButton__languageModeLabel">Language</div>
            <div class="ToolButton__languageModeButtons">
                <a class="ToolButton__languageModeButton"
                    href="../../blog/2024-08-01-ReazonSpeech.html">JP</a>
                /
                <a class="ToolButton__languageModeButton" disabled
                    href=".././en/blog/2024-08-01-ReazonSpeech.html">EN</a>
            </div>
        </div>
-->
    </div>
</footer><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
  <script src="../_static/jquery.js"></script>
  <script src="../_static/underscore.js"></script>
  <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
  <script src="../_static/doctools.js"></script>
  <script src="../_static/sphinx_highlight.js"></script>
  <!-- <script type="module" crossorigin src="http://localhost:3000/javascripts/main.ts"></script> -->
  <script src="../_static/main.js" defer></script></body>

</html>