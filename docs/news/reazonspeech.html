<!doctype html>
<html class="no-js"  lang="ja" >

<head><meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<meta content="株式会社レアゾン・ホールディングスは、2023年1月18日、世界最高レベルの高精度日本語音声認識モデルおよび世界最大19,000時間の日本語音声コーパス「ReazonSpeech」を公開しました。" name="description" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-S1KMDX1V1H"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-S1KMDX1V1H');
    </script>
    
  <link rel="author" title="このドキュメントについて" href="../about.html" /><link rel="index" title="索引" href="../genindex.html" /><link rel="search" title="検索" href="../search.html" /><link rel="next" title="Blog" href="../blog/index.html" /><link rel="prev" title="News" href="index.html" />
  <link rel="canonical" href="https://research.reazon.jp/news/reazonspeech.html" />
  
  <title>超高精度で商用利用可能な純国産の日本語音声認識モデル「ReazonSpeech」を無償公開 - Reazon Human Interaction Lab</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Condensed:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
  <link rel="stylesheet" type="text/css" href="../_static/style.css" />
  <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
  </head>

<body id="news-reazonspeech">
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
    <symbol id="svg-arrow" viewBox="0 0 14 8">
      <svg viewBox="0 0 14 8" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7 2.82801L2.05 7.77801L0.635998 6.36401L7 1.47024e-05L13.364 6.36402L11.95 7.77802L7 2.82801Z"
          fill="currentColor" />
      </svg>
    </symbol>
    <symbol id="svg-toc-menu">
      <svg width="19" height="17" viewBox="0 0 19 17" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path
          d="M19 15V17H1V15H19ZM4.596 0.903999L6.01 2.318L2.828 5.5L6.01 8.682L4.596 10.096L0 5.5L4.596 0.903999ZM19 8V10H10V8H19ZM19 0.999999V3H10V0.999999H19Z"
          fill="currentColor" />
      </svg>
    </symbol>
    <symbol id="svg-close">
      <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path
          d="M8 6.2225L14.2225 0L16 1.7775L9.7775 8L16 14.2225L14.2225 16L8 9.7775L1.7775 16L0 14.2225L6.2225 8L0 1.7775L1.7775 0L8 6.2225Z"
          fill="currentColor" />
      </svg>
    </symbol>
    <symbol id="svg-arrow-left">
      <svg width="10" height="17" viewBox="0 0 10 17" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M3.6359 8.5L10 15.1114L8.18205 17L5.82128e-07 8.5L8.18205 -7.9465e-08L10 1.88859L3.6359 8.5Z"
          fill="currentColor" />
      </svg>
    </symbol>
  </svg>
  <div id="global_nav"></div>
  <div class="Container">
    <aside id="sidebar" class="Sidebar" aria-label="Sidebar">
    <div class="Sidebar__animationBg"></div>
    <div class="Sidebar__container">
        <div class="Sidebar__inner">
            <a class="Sidebar__logo" href="../index.html">
                
                <h1>
                    <img class="Sidebar__logoImage--light" src="../_static/logo.png" />
                    <img class="Sidebar__logoImage--dark" src="../_static/logo-dark.png" />
                </h1>
                
            </a>
            <div class="Sidebar__tree Tree"><ul class="current">
<li class="toctree-l1 Tree__item"><a class="reference internal" href="../about.html">About</a></li>
<li class="toctree-l1 Tree__item Tree__item--has-children"><a class="reference internal" href="../projects/index.html">Projects</a><input class="Tree_itemToggleCheckbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="Tree__itemToggle" for="toctree-checkbox-1"><i class="Tree__itemToggleIcon"><svg><use href="#svg-arrow"></use></svg></i></label><ul>
<li class="toctree-l2 Tree__item Tree__item--has-children"><a class="reference internal" href="../projects/ReazonSpeech/index.html">ReazonSpeech</a><input class="Tree_itemToggleCheckbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="Tree__itemToggle" for="toctree-checkbox-2"><i class="Tree__itemToggleIcon"><svg><use href="#svg-arrow"></use></svg></i></label><ul>
<li class="toctree-l3 Tree__item"><a class="reference internal" href="../projects/ReazonSpeech/quickstart.html">クイックスタート</a></li>
<li class="toctree-l3 Tree__item"><a class="reference internal" href="../projects/ReazonSpeech/howto.html">HowToガイド</a></li>
<li class="toctree-l3 Tree__item Tree__item--has-children"><a class="reference internal" href="../projects/ReazonSpeech/api/index.html">APIリファレンス</a><input class="Tree_itemToggleCheckbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="Tree__itemToggle" for="toctree-checkbox-3"><i class="Tree__itemToggleIcon"><svg><use href="#svg-arrow"></use></svg></i></label><ul>
<li class="toctree-l4 Tree__item"><a class="reference internal" href="../projects/ReazonSpeech/api/reazonspeech.nemo.asr.html">reazonspeech.nemo.asr</a></li>
<li class="toctree-l4 Tree__item"><a class="reference internal" href="../projects/ReazonSpeech/api/reazonspeech.k2.asr.html">reazonspeech.k2.asr</a></li>
<li class="toctree-l4 Tree__item"><a class="reference internal" href="../projects/ReazonSpeech/api/reazonspeech.espnet.asr.html">reazonspeech.espnet.asr</a></li>
<li class="toctree-l4 Tree__item"><a class="reference internal" href="../projects/ReazonSpeech/api/reazonspeech.espnet.oneseg.html">reazonspeech.espnet.oneseg</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current Tree__item Tree__item--has-children"><a class="reference internal" href="index.html">News</a><input checked="" class="Tree_itemToggleCheckbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="Tree__itemToggle" for="toctree-checkbox-4"><i class="Tree__itemToggleIcon"><svg><use href="#svg-arrow"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current Tree__item current-page"><a class="current reference internal" href="#">超高精度で商用利用可能な純国産の日本語音声認識モデル「ReazonSpeech」を無償公開</a></li>
</ul>
</li>
<li class="toctree-l1 Tree__item Tree__item--has-children"><a class="reference internal" href="../blog/index.html">Blog</a><input class="Tree_itemToggleCheckbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="Tree__itemToggle" for="toctree-checkbox-5"><i class="Tree__itemToggleIcon"><svg><use href="#svg-arrow"></use></svg></i></label><ul>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="../blog/2024-11-06-openarm-study-group-01.html">(2024-11-06) 第1回 OpenArm勉強会を開催しました!</a></li>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="../blog/2024-10-21-Wav2Vec2-base-release.html">(2024-10-21) 大規模日本語音声による事前学習モデルWav2Vec2を公開</a></li>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="../blog/2024-08-01-ReazonSpeech.html">(2024-08-01) ReazonSpeech v2.1: Setting a New Standard in Japanese ASR</a></li>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="../blog/2024-03-02-how-to-run-aloha-developers.agirobots.com.html">(2024-03-02) ALOHAとACTを用いた模倣学習実験の再現方法</a></li>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="../blog/2024-02-14-ReazonSpeech.html">(2024-02-14) ReazonSpeech v2.0: 音声モデルの高速化とコーパスの大幅な拡大</a></li>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="../blog/2023-04-04-ReazonSpeech.html">(2023-04-04) ReazonSpeechの最新モデルを公開しました</a></li>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="../blog/2023-01-15-ReazonSpeech-ESP32.html">(2023-01-15) スマホの通話内容をReazonSpeechで音声認識してSlackに転送する</a></li>
<li class="toctree-l2 Tree__item"><a class="reference internal" href="../blog/2023-01-15-DDS-performance.html">(2023-01-15) 分散ROS2 FastDDS/CycloneDDS のパフォーマンス評価</a></li>
</ul>
</li>
<li class="toctree-l1 Tree__item"><a class="reference internal" href="../publications.html">Publications</a></li>
<li class="toctree-l1 Tree__item"><a class="reference internal" href="../careers.html">Careers</a></li>
</ul>
</div>
            <div class="Sidebar__search Search">
                <i class="Search__icon">
                    <svg width="22" height="21" viewBox="0 0 21 21" fill="none" xmlns="http://www.w3.org/2000/svg">
                        <path
                            d="M16.031 14.617L20.314 18.899L18.899 20.314L14.617 16.031C13.0237 17.3082 11.042 18.0029 9 18C4.032 18 0 13.968 0 9C0 4.032 4.032 0 9 0C13.968 0 18 4.032 18 9C18.0029 11.042 17.3082 13.0237 16.031 14.617ZM14.025 13.875C15.2941 12.5699 16.0029 10.8204 16 9C16 5.132 12.867 2 9 2C5.132 2 2 5.132 2 9C2 12.867 5.132 16 9 16C10.8204 16.0029 12.5699 15.2941 13.875 14.025L14.025 13.875Z"
                            fill="currentColor" />
                    </svg>
                </i>
                <form class="Search__form" method="get" action="../search.html" role="search">
                    <input class="Search__formText" placeholder=" Search" name="q" aria-label=" Search" />
                    <input type="hidden" name="check_keywords" value="yes" />
                    <input type="hidden" name="area" value="default" />
                </form>
            </div>
        </div>
    </div>
</aside>
    <div class="Container__inner">
      
      <script>document.body.dataset.theme = localStorage.getItem("theme") || "auto";</script>



<main class="Page">
    <header class="Page__header">
        
        <div class="Page__headerParent">News：</div>
        
        <h1>超高精度で商用利用可能な純国産の日本語音声認識モデル「ReazonSpeech」を無償公開 </h1>
        
    </header>
    <article class="Page__body">
        <section id="reazonspeech">
<h1>超高精度で商用利用可能な純国産の日本語音声認識モデル「ReazonSpeech」を無償公開<a class="headerlink" href="#reazonspeech" title="この見出しへのパーマリンク">¶</a></h1>
<figure class="align-default">
<a class="reference internal image-reference" href="../_images/hilab_logo.png"><img alt="../_images/hilab_logo.png" src="../_images/hilab_logo.png" style="width: 300px;" /></a>
</figure>
<p>〜音声認識の新しい&quot;当たり前&quot;をひらく〜</p>
<p>株式会社レアゾン・ホールディングス(本社：東京都新宿区、代表取締役：渡邉 真)は、2023年1月18日、世界最高レベルの高精度日本語音声認識モデルおよび世界最大19,000時間の日本語音声コーパス※「ReazonSpeech」を公開しました。</p>
<blockquote>
<div><p>※音声コーパス: 音声データとテキストデータを発話単位で対応付けて集めたもの。音声認識モデルを作成する材料として使用され、その規模と品質が音声認識の精度を大きく左右する。</p>
</div></blockquote>
<p>「ReazonSpeech」を用いた文字起こしサービスをプロジェクトwebサイトで実際に試すことができます。</p>
<blockquote>
<div><p>URL　　    <a class="reference external" href="https://research.reazon.jp/projects/ReazonSpeech/">https://research.reazon.jp/projects/ReazonSpeech/</a></p>
</div></blockquote>
<section id="id1">
<h2>「ReazonSpeech」とは<a class="headerlink" href="#id1" title="この見出しへのパーマリンク">¶</a></h2>
<p>「ReazonSpeech」は、レアゾン・ヒューマンインタラクション研究所が開発した高精度な音声認識モデルを中心とするプロダクト群で、それぞれ以下のような特徴があります。</p>
<ul class="simple">
<li><p>ReazonSpeech音声認識モデル: OpenAI Whisper※に匹敵する高精度な日本語音声認識モデル。商用利用可</p></li>
<li><p>ReazonSpeechコーパス作成ツール: TV録画データ等から音声コーパスを自動抽出するソフトウェアツール。商用利用可</p></li>
<li><p>ReazonSpeech音声コーパス: 世界最大19,000時間の高品質な日本語音声認識モデル学習用コーパス</p></li>
<li><p>いずれも無償にて公開</p></li>
</ul>
<blockquote>
<div><p>※OpenAI Whisper: ChatGPTなど最先端のAIプロダクトを次々に発表している米国の人工知能研究所OpenAIが2022年9月に公開した高精度な音声認識モデル。従来の多くの音声認識モデルの精度を凌駕しているとして大きな話題を呼んだ。</p>
</div></blockquote>
<figure class="align-default" id="id9">
<a class="reference internal image-reference" href="../_images/colab_demo.png"><img alt="../_images/colab_demo.png" src="../_images/colab_demo.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-text">[図] ReazonSpeech音声認識モデル使用例</span><a class="headerlink" href="#id9" title="この画像へのパーマリンク">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id10">
<a class="reference internal image-reference" href="../_images/fig21.png"><img alt="../_images/fig21.png" src="../_images/fig21.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-text">[図] スマホの通話内容をReazonSpeechを使ってリアルタイムで自動文字起こししてslackに記録する例</span><a class="headerlink" href="#id10" title="この画像へのパーマリンク">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id2">
<h2>開発の背景<a class="headerlink" href="#id2" title="この見出しへのパーマリンク">¶</a></h2>
<p>近年、深層学習を用いた音声認識技術は飛躍的に精度が向上し、スマート端末等を通して多くの人がこの技術を利用できるようになりました。今後さらに技術が普及し、誰もがあらゆる端末やシチュエーションで最先端の音声認識技術を当たり前のように使えるようになれば、社会の様々な局面でコミュニケーションの質を高めたり、業務効率や生産性の改善に貢献することが期待されます。</p>
<p>深層学習を用いた音声認識では、高精度な音声認識モデルを得るために、音声コーパスが大量に揃っていることが必要不可欠となります。誰もが自由に使える形で大規模な音声コーパスが公開されれば、当技術の迅速な発展に大きく寄与します。英語等ではこうした音声コーパスが多数公開されていますが、日本語では商用利用も含めて自由に利用可能なコーパスは量が少なく、日本語における音声認識技術の発展と普及を妨げる大きな要因となっていました。</p>
</section>
<section id="id3">
<h2>「ReazonSpeech」の方式<a class="headerlink" href="#id3" title="この見出しへのパーマリンク">¶</a></h2>
<p>「ReazonSpeech」では、ワンセグ放送の録画データから音声コーパスを自動抽出しています。
録画データから音声コーパスを構築するためには、発話単位で音声と字幕テキストを対応付ける処理(アラインメント処理と呼びます)が必要になります。大規模なデータに対して手動でアラインメント処理を行うと膨大なコストがかってしまいます。既存の音声認識モデルを利用すればアラインメント処理を自動化することができますが、その結果として得られた音声コーパスは、元の音声認識モデルやその学習に用いた音声コーパスのライセンスの影響を受けてしまいます。</p>
<p>そこで「ReazonSpeech」では、まず最初に小規模ではあるものの自由なライセンスで利用可能な <a class="reference external" href="https://commonvoice.mozilla.org/">Mozilla Common Voice</a> という音声コーパスから構築した音声認識モデルでアラインメント処理を行い、そこで得られた音声コーパスを元にして再度アラインメント処理を実行する、という過程を幾世代も重ねることによって少しずつ音声コーパスのサイズを増やしました。現在のサイズは19,000時間ですが、今後さらに規模を拡大する予定です。</p>
</section>
<section id="id4">
<h2>関連技術との比較<a class="headerlink" href="#id4" title="この見出しへのパーマリンク">¶</a></h2>
<p>「ReazonSpeech」コーパスを用いて構築した <a class="reference external" href="https://github.com/espnet/espnet">ESPnet</a> ※音声認識モデルと、他の主要な音声認識モデルである <a class="reference external" href="https://github.com/openai/whisper">OpenAI Whisper</a> , <a class="reference external" href="https://github.com/laboroai/LaboroTVSpeech">LaboroTVSpeech</a> との精度比較結果を示します。</p>
<blockquote>
<div><p>※ESPnet: E2E音声処理のためのオープンソースツールキット。渡部晋治氏をリーダーとして、様々な大学や研究機関、企業に属する日本人が中心となって開発。ライセンスはApache-2.0で、商用利用も可能。</p>
</div></blockquote>
<figure class="align-default">
<a class="reference internal image-reference" href="../_images/reazonspeech_cer.jpg"><img alt="../_images/reazonspeech_cer.jpg" src="../_images/reazonspeech_cer.jpg" style="width: 500px;" /></a>
</figure>
<p>一般に音声認識モデルのパラメータ数と精度はトレードオフの関係にありますが、ESPnet ReazonSpeech は、少ないパラメータ数で Whisper large-v2 と同等の精度を達成しています。</p>
<figure class="align-default" id="id11">
<a class="reference internal image-reference" href="../_images/reazonspeech_modelparams.png"><img alt="../_images/reazonspeech_modelparams.png" src="../_images/reazonspeech_modelparams.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-text">[図] Common VoiceでのCER音声認識精度(小さいほど良い) vs モデルパラメータ数(少ないほど良い)</span><a class="headerlink" href="#id11" title="この画像へのパーマリンク">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id5">
<h2>ライセンス<a class="headerlink" href="#id5" title="この見出しへのパーマリンク">¶</a></h2>
<p>音声認識モデルと音声コーパス作成ツールはApacheライセンス2.0にて公開するので、商用・非商用を問わず、誰もが自由に利用・改変・再配布し、同様のコーパスの構築・共有活動に参加できるようになります。</p>
<p>音声コーパスについては、 <a class="reference external" href="https://cdla.dev/sharing-1-0/">CDLA-Sharing-1.0</a> ライセンス(著作権法30条の4を含む適用法令を遵守し、原著作権者の権利を侵害しないことが前提※)にて公開しています。</p>
<p>※放送録画データに含まれる音声及び字幕データの権利は、元のテレビ放送の著作権者に帰属しますが、このデータを機械学習モデル構築のために使用することは、商用・非商用の目的を問わず著作権法30条の4によって認められています。</p>
<figure class="align-default">
<a class="reference internal image-reference" href="../_images/reazonspeech_license.jpg"><img alt="../_images/reazonspeech_license.jpg" src="../_images/reazonspeech_license.jpg" style="width: 500px;" /></a>
</figure>
</section>
<section id="id6">
<h2>今後の予定<a class="headerlink" href="#id6" title="この見出しへのパーマリンク">¶</a></h2>
<ul class="simple">
<li><p>言語処理学会第29回年次大会(NLP2023)で今回の成果について報告</p></li>
<li><p>より大規模で高品質な音声コーパスの継続的なリリース</p></li>
<li><p>多くの人が自由な音声コーパスの構築と共有に参加するための普及活動の実施</p></li>
</ul>
</section>
<section id="id7">
<h2>レアゾン・ヒューマンインタラクション研究所について<a class="headerlink" href="#id7" title="この見出しへのパーマリンク">¶</a></h2>
<p>レアゾン・ヒューマンインタラクション研究所は株式会社レアゾン・ホールディングスの企業研究所です。</p>
<p>音声・視線・手や身体を用いたジェスチャーの認識や、マニピュレータや道具・楽器等の操作、協働ロボット技術など あらゆるユーザがより効率的に情報伝達を行うための技術について幅広く研究し、その成果を速やかに公開して、当該分野の研究と実用化の迅速な発展に貢献することを目指しています。
現在、研究員を募集しています。</p>
<blockquote>
<div><p>URL　　    <a class="reference external" href="https://research.reazon.jp">https://research.reazon.jp</a></p>
</div></blockquote>
</section>
<section id="id8">
<h2>レアゾン・ホールディングスについて<a class="headerlink" href="#id8" title="この見出しへのパーマリンク">¶</a></h2>
<p>「新しい&quot;当たり前&quot;を作り続ける世界一の企業へ」を掲げ、「アドテク事業」、「ソーシャルゲーム事業」、「メディア事業」、「フードテック事業」の4つの領域を中心に事業を展開しています。各事業領域同士で事業シナジーを高めることで、他社にはない事業展開や新規事業を創出し続けます。</p>
<div class="table-wrapper docutils container" id="id12">
<table class="docutils align-left" id="id12">
<caption><span class="caption-text">■会社概要</span><a class="headerlink" href="#id12" title="このテーブルへのパーマリンク">¶</a></caption>
<tbody>
<tr class="row-odd"><td><p>商号</p></td>
<td><p>株式会社レアゾン・ホールディングス</p></td>
</tr>
<tr class="row-even"><td><p>代表者</p></td>
<td><p>代表取締役　渡邉 真</p></td>
</tr>
<tr class="row-odd"><td><p>所在地</p></td>
<td><p>〒164-0004　東京都新宿区四谷1-6-1</p></td>
</tr>
<tr class="row-even"><td><p>設立</p></td>
<td><p>2019年2月</p></td>
</tr>
<tr class="row-odd"><td><p>事業内容</p></td>
<td><p>グループの経営戦略、経営管理・事業支援</p></td>
</tr>
<tr class="row-even"><td><p>URL</p></td>
<td><p><a class="reference external" href="https://reazon.jp/">https://reazon.jp/</a></p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>

    </article>
    <aside class="Page__toc Toc">
        
        
        <div class="Toc__inner">
            <div class="Toc__title">
                <span>Index</span>
            </div>
            <div class="Toc__tree">
                <ul>
<li><a class="reference internal" href="#">超高精度で商用利用可能な純国産の日本語音声認識モデル「ReazonSpeech」を無償公開</a><ul>
<li><a class="reference internal" href="#id1">「ReazonSpeech」とは</a></li>
<li><a class="reference internal" href="#id2">開発の背景</a></li>
<li><a class="reference internal" href="#id3">「ReazonSpeech」の方式</a></li>
<li><a class="reference internal" href="#id4">関連技術との比較</a></li>
<li><a class="reference internal" href="#id5">ライセンス</a></li>
<li><a class="reference internal" href="#id6">今後の予定</a></li>
<li><a class="reference internal" href="#id7">レアゾン・ヒューマンインタラクション研究所について</a></li>
<li><a class="reference internal" href="#id8">レアゾン・ホールディングスについて</a></li>
</ul>
</li>
</ul>

            </div>
        </div>
        
        
    </aside>
</main>

    </div>
  </div>
  <footer class="Footer">
    <div class="Footer__copyright">
        Copyright &copy; 2023, Human Interaction Laboratory
    </div>
    <div class="Footer__toolButton ToolButton">
        <div class="ToolButton__viewMode">
            <div class="ToolButton__viewModeLabel">View Mode</div>
            <button class="ToolButton__viewModeButton ToolButton__viewModeButton--dark">Night Mode</button>
            <button class="ToolButton__viewModeButton ToolButton__viewModeButton--light">Day Mode</button>
            <button class="ToolButton__viewModeButton ToolButton__viewModeButton--system">System Setting</button>
        </div>
<!--
        <div class="ToolButton__languageMode">
            <div class="ToolButton__languageModeLabel">Language</div>
            <div class="ToolButton__languageModeButtons">
                <a class="ToolButton__languageModeButton" disabled
                    href="../../news/reazonspeech.html">JP</a>
                /
                <a class="ToolButton__languageModeButton"
                    href=".././en/news/reazonspeech.html">EN</a>
            </div>
        </div>
-->
    </div>
</footer><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
  <script src="../_static/jquery.js"></script>
  <script src="../_static/underscore.js"></script>
  <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
  <script src="../_static/doctools.js"></script>
  <script src="../_static/sphinx_highlight.js"></script>
  <script src="../_static/translations.js"></script>
  <!-- <script type="module" crossorigin src="http://localhost:3000/javascripts/main.ts"></script> -->
  <script src="../_static/main.js" defer></script></body>

</html>